{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdxKKYkJwo+zFDBzg+kyDz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JianchengSun826/SummerCamp/blob/Jason/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYL9exFSPVMY"
      },
      "outputs": [],
      "source": [
        "# Predefined sentiment keywords and scores\n",
        "sentiment_dict = {\n",
        "    \"good\": 1,\n",
        "    \"happy\": 1,\n",
        "    \"great\": 1,\n",
        "    \"excellent\": 1,\n",
        "    \"awesome\": 1,\n",
        "    \"love\": 1,\n",
        "    \"bad\": -1,\n",
        "    \"sad\": -1,\n",
        "    \"terrible\": -1,\n",
        "    \"awful\": -1,\n",
        "    \"hate\": -1,\n",
        "    \"horrible\": -1,\n",
        "    \"ok\": 0,\n",
        "    \"neutral\": 0,\n",
        "    \"indifferent\": 0,\n",
        "    \"normal\": 0,\n",
        "    \"standard\": 0,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "    \"\"\"\n",
        "    Analyzes the sentiment score of the given text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input sentence or paragraph.\n",
        "\n",
        "    Returns:\n",
        "        int: Sentiment classification: 1 (positive), -1 (negative), or 0 (neutral)\n",
        "    \"\"\"\n",
        "    words = text.lower().split()\n",
        "    score = 0\n",
        "\n",
        "    for word in words:\n",
        "        if word in sentiment_dict:\n",
        "            score += sentiment_dict[word]\n",
        "\n",
        "    # Decide final sentiment\n",
        "    if score > 0:\n",
        "        return 1\n",
        "    elif score < 0:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n"
      ],
      "metadata": {
        "id": "Ewn-PmHqpXPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"I love this awesome day\",\n",
        "    \"This is a terrible experience\",\n",
        "    \"It was just an average time\",\n",
        "    \"I feel happy and great\",\n",
        "    \"That movie was horrible and awful\",\n",
        "]\n",
        "\n",
        "for text in texts:\n",
        "    result = analyze_sentiment(text)\n",
        "    print(f\"Text: {text}\\nSentiment: {result}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBHLt0wapUdG",
        "outputId": "0aed95bc-04d9-40fa-fce4-b554b3e3a91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I love this awesome day\n",
            "Sentiment: 1\n",
            "\n",
            "Text: This is a terrible experience\n",
            "Sentiment: -1\n",
            "\n",
            "Text: It was just an average time\n",
            "Sentiment: 0\n",
            "\n",
            "Text: I feel happy and great\n",
            "Sentiment: 1\n",
            "\n",
            "Text: That movie was horrible and awful\n",
            "Sentiment: -1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "8zetOfymZneW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Use Afinn package to return the sentiment of some sentences are positive, negative or neutral"
      ],
      "metadata": {
        "id": "_QYJnOFSahOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install afinn"
      ],
      "metadata": {
        "id": "917iYWB0bLPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "264808e0-e48a-4e65-8ee2-3829ed46e036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting afinn\n",
            "  Downloading afinn-0.1.tar.gz (52 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-py3-none-any.whl size=53431 sha256=eb621c8bc89a8e5197e0b79b6b70b1892c3587c8f97c84f5620cf0651c6430cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/d3/a0/f9255ebac29886acb1c28b35b37523f6399677fa06be379f25\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "from afinn import Afinn\n",
        "import pandas as pd\n",
        "\n",
        "#instantiate afinn\n",
        "afn = Afinn()\n",
        "\n",
        "#creating list sentences\n",
        "news_df = ['les gens pensent aux chiens','i hate flowers',\n",
        "         'he is kind and smart','we are kind to good people']\n",
        "\n",
        "# compute scores (polarity) and labels\n",
        "# scores = [afn.score(sentence) for sentence in news_df]\n",
        "scores = []\n",
        "for sentence in news_df:\n",
        "    scores.append(afn.score(sentence))\n",
        "# sentiment = ['positive' if score > 0\n",
        "#                           else 'negative' if score < 0\n",
        "#                               else 'neutral'\n",
        "#                                   for score in scores]\n",
        "sentiment = []\n",
        "for score in scores:\n",
        "    if score > 0:\n",
        "        sentiment.append('positive')\n",
        "    elif score < 0:\n",
        "        sentiment.append('negative')\n",
        "    else:\n",
        "        sentiment.append('neutral')\n",
        "\n",
        "# dataframe creation\n",
        "df = pd.DataFrame()\n",
        "df['topic'] =  news_df\n",
        "df['scores'] = scores\n",
        "df['sentiments'] = sentiment\n",
        "print(df)"
      ],
      "metadata": {
        "id": "RuGfVz-5cZVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee6a1ad-6192-4fc1-80de-45db24f3b830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         topic  scores sentiments\n",
            "0  les gens pensent aux chiens     0.0    neutral\n",
            "1               i hate flowers    -3.0   negative\n",
            "2         he is kind and smart     3.0   positive\n",
            "3   we are kind to good people     5.0   positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. NLTK sentiment analysis and POS Tag (tokenize)"
      ],
      "metadata": {
        "id": "g4wH2GHdbpa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sentiment analysis\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "text = \"NLTK is a great library for text processing!\"\n",
        "sentiment_scores = sid.polarity_scores(text)\n",
        "print(sentiment_scores)"
      ],
      "metadata": {
        "id": "NhY9sWJzggTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef115896-61ae-4325-d4aa-0ab78f1227e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.577, 'pos': 0.423, 'compound': 0.6588}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Tag\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"The quick brown fox jumps over the lazy dog near the river.\"\n",
        "\n",
        "# Tokenize and POS tag\n",
        "words = word_tokenize(sentence)\n",
        "tagged_words = pos_tag(words)\n",
        "\n",
        "# Extract nouns (NN, NNS, NNP, NNPS)\n",
        "nouns = [word for word, tag in tagged_words if tag in ['NN', 'NNS', 'NNP', 'NNPS']]\n",
        "\n",
        "print(\"Extracted Nouns:\", nouns)\n"
      ],
      "metadata": {
        "id": "RLY-277ChPbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018c01a4-6cfa-4ba2-cf3e-974ddff465b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Nouns: ['brown', 'fox', 'dog', 'river']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_DthQiJyjADa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}